# MANAGEMENT POLICIES
ClusterName=<%= $cluster_name %>
AuthType=auth/munge
CryptoType=crypto/munge
SlurmUser=slurm
{{ range service "slurmctld" -}}
SlurmctldHost={{ .Node }}({{ .Address }})
{{ end -}}
# SCHEDULER CONFIGURATIONS
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Core_Memory

# NODE CONFIGURATIONS
GresTypes=gpu
{{ if service "slurmd" -}}
include /etc/slurm/node.conf
{{ else }}
NodeName=node1 State=down
{{ end -}}

# PARTITION CONFIGURATIONS
DisableRootJobs=YES
PartitionName=cpubase_bycore_b1 Nodes=ALL Default=YES DefaultTime=1:00:00 DefMemPerCPU=256 OverSubscribe=YES

SlurmctldPort=6817
SlurmdPort=6818

SlurmctldDebug=debug
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=debug
SlurmdLogFile=/var/log/slurm/slurmd.log

SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid

# JOBS AND TASKS/RESOURCES CONTROL
TmpFS=/localscratch
PrologFlags=contain
# Prolog=/etc/slurm/prolog
Epilog=/etc/slurm/epilog
PlugStackConfig=/etc/slurm/plugstack.conf
MpiDefault=pmi2
ProctrackType=proctrack/cgroup
TaskPlugin=task/cgroup

StateSaveLocation=/var/spool/slurm
<% if $slurm_version == 19 { -%>
SallocDefaultCommand="srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --mpi=none bash"
<% } elsif $slurm_version == 20 { -%>
InteractiveStepOptions="--interactive --mem-per-cpu=0 --preserve-env --pty $SHELL"
LaunchParameters=use_interactive_step
<% } -%>

## Accounting
{{ range service "slurmdbd" -}}
AccountingStorageHost={{ .Node }}
{{ end -}}
{{ if service "slurmdbd" -}}
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageTRES=gres/gpu,cpu,mem
#AccountingStorageEnforce=limits
JobAcctGatherType=jobacct_gather/cgroup
JobAcctGatherFrequency=task=30
JobAcctGatherParams=NoOverMemoryKill,UsePSS
{{ end -}}
