include /etc/slurm/slurm-consul.conf
include /etc/slurm/nodes.conf

# MANAGEMENT POLICIES
ClusterName=<%= $cluster_name %>
AuthType=auth/munge
CryptoType=crypto/munge
SlurmUser=slurm
# SCHEDULER CONFIGURATIONS
SchedulerType=sched/backfill
SelectType=select/cons_tres
SelectTypeParameters=CR_Core_Memory

# NODE CONFIGURATIONS
GresTypes=gpu

TreeWidth=<%= $nb_nodes %>
ReturnToService=2 # A DOWN node will become available for use upon registration with a valid configuration.
RebootProgram=/usr/sbin/reboot
ResumeProgram=/usr/bin/slurm_resume
SuspendProgram=/usr/bin/slurm_suspend
ResumeFailProgram=/usr/bin/slurm_suspend
ResumeTimeout=<%= $resume_timeout %>
SuspendTime=<%= $suspend_time %>
SuspendRate=20
ResumeRate=20
<% if $suspend_exc_nodes != '' { -%>
SuspendExcNodes=<%= $suspend_exc_nodes %>
<% } -%>

SchedulerParameters=salloc_wait_nodes
SlurmctldParameters=idle_on_node_suspend,cloud_dns
CommunicationParameters=NoAddrCache

# PARTITION CONFIGURATIONS
DisableRootJobs=YES
PartitionName=DEFAULT DefaultTime=1:00:00 DefMemPerCPU=256 OverSubscribe=YES
PartitionName=cpubase_bycore_b1 Default=YES Nodes=ALL
<% $partitions.map|$name, $values| { -%>
PartitionName=<%= $name %> Nodes=<%= join($values['nodes'], ',') %>
<% } -%>

SlurmdPort=6818

SlurmctldDebug=debug
SlurmctldLogFile=/var/log/slurm/slurmctld.log
SlurmdDebug=debug
SlurmdLogFile=/var/log/slurm/slurmd.log

SlurmctldPidFile=/var/run/slurmctld.pid
SlurmdPidFile=/var/run/slurmd.pid

# JOBS AND TASKS/RESOURCES CONTROL
TmpFS=/localscratch
<% if $enable_x11_forwarding { -%>
PrologFlags=alloc,contain,x11
X11Parameters=home_xauthority
<% } else { -%>
PrologFlags=alloc,contain
<% } -%>
# Prolog=/etc/slurm/prolog
Epilog=/etc/slurm/epilog
PlugStackConfig=/etc/slurm/plugstack.conf
MpiDefault=pmi2
ProctrackType=proctrack/cgroup
<% if versioncmp($slurm_version, '21.08') >= 0 { -%>
TaskPlugin=task/affinity,task/cgroup
<% } else { -%>
TaskPlugin=task/cgroup
<% } -%>
PropagateResourceLimits=NONE
MailProg=/usr/sbin/slurm_mail

StateSaveLocation=/var/spool/slurm
InteractiveStepOptions="--interactive --mem-per-cpu=0 --preserve-env --pty $SHELL"
LaunchParameters=use_interactive_step,disable_send_gids
<% if versioncmp($slurm_version, '21.08') >= 0 { -%>
JobSubmitPlugins=lua
<% } -%>

<% if versioncmp($slurm_version, '23.02') < 0 { -%>
# The autoscaling compute nodes are not showed by sinfo unless we set PrivateData=cloud
# Not needed for Slurm >= 23.02
PrivateData=cloud
<% } -%>

include /etc/slurm/slurm-addendum.conf
