---
lookup_options:
  profile::users::ldap::users:
    merge: 'deep'
  profile::users::local::users:
    merge: 'deep'
  jupyterhub::jupyterhub_config_hash:
    merge: 'deep'
  prometheus::alerts:
    merge: 'deep'

profile::base::version: 14.0.0
profile::base::packages: []

motd::content: ""

consul_template::version: 0.25.2
consul::version: 1.15.2
consul_template::config_hash:
  consul:
    token: "%{hiera('profile::consul::acl_api_token')}"

epel::epel_exclude: 'slurm*'
epel::epel_source_managed: false
epel::epel_debuginfo_managed: false
epel::epel_testing_managed: false
epel::epel_testing_source_managed: false
epel::epel_testing_debuginfo_managed: false

fail2ban::package_name: fail2ban-server
fail2ban::jails: ['ssh-route', 'ssh-ban-root']
fail2ban::custom_jails:
  'ssh-route':
    enabled: true
    filter: 'sshd'
    findtime: 3600
    bantime: 86400
    maxretry: 20
    action: 'route'
    logpath: '%(sshd_log)s'
  'ssh-ban-root':
    enabled: true
    findtime: 3600
    bantime: 86400
    maxretry: 0
    action: 'route'
    logpath: '%(sshd_log)s'
    journalmatch: '_SYSTEMD_UNIT=sshd.service + _COMM=sshd'
    filter_maxlines: 10
    filter_includes: 'before = common.conf'
    filter_failregex: '^%(__prefix_line)spam_unix\(sshd:auth\):\s+authentication failure;\s*logname=\S*\s*uid=\d*\s*euid=\d*\s*tty=\S*\s*ruser=\S*\s*rhost=<HOST>\S*\s*user=(root|admin)\s.*$'

jupyterhub::kernel::setup: venv
jupyterhub::jupyterhub_config_hash:
  SlurmFormSpawner:
    ui_args:
      notebook:
        name: Jupyter Notebook
        args: ['--SingleUserNotebookApp.default_url=/tree']
      lab:
        name: JupyterLab
      terminal:
        name: Terminal
        args: ['--SingleUserNotebookApp.default_url=/terminals/1']
      rstudio:
        name: RStudio
        args: ['--SingleUserNotebookApp.default_url=/rstudio']
      code-server:
        name: VS Code
        args: ['--SingleUserNotebookApp.default_url=/code-server']
      desktop:
        name: Desktop
        args: ['--SingleUserNotebookApp.default_url=/Desktop']

  SbatchForm:
    ui:
      choices: ['notebook', 'lab', 'terminal', 'code-server', 'desktop']
      def: 'lab'

selinux::mode: 'permissive'
# selinux::type: 'targeted'

squid::cache_mem: "256 MB"
squid::extra_config_sections:
  general:
    config_entries:
      maximum_object_size: "131072 KB"

swap_file::files:
  default:
    ensure: "present"
    swapfile: "/mnt/swap"
    swapfilesize: "1 GB"


mysql::server::remove_default_accounts: true
mysql::server::override_options:
    mysqld:
      innodb_buffer_pool_size: 1024M
      innodb_log_file_size: 64M
      innodb_lock_wait_timeout: 900

prometheus::alerts:
  groups:
    - name: 'recorder.rules'
      rules:
      - record: slurm_job:allocated_core:count
        expr: count(slurm_job_core_usage_total)
      - record: slurm_job:allocated_core:count_user_account
        expr: count(slurm_job_core_usage_total) by (user,account)
      - record: slurm_job:used_core:sum
        expr: sum(rate(slurm_job_core_usage_total{}[2m]) / 1000000000)
      - record: slurm_job:used_core:sum_user_account
        expr: sum(rate(slurm_job_core_usage_total{}[2m]) / 1000000000) by (user,account)
      - record: slurm_job:allocated_memory:sum
        expr: sum(slurm_job_memory_limit{})
      - record: slurm_job:allocated_memory:sum_user_account
        expr: sum(slurm_job_memory_limit{}) by (user,account)
      - record: slurm_job:rss_memory:sum
        expr: sum(slurm_job_memory_rss)
      - record: slurm_job:rss_memory:sum_user_account
        expr: sum(slurm_job_memory_rss) by (user, account)
      - record: slurm_job:max_memory:sum_user_account
        expr: sum(slurm_job_memory_max) by (user, account)
      - record: slurm_job:allocated_gpu:count
        expr: count(slurm_job_utilization_gpu)
      - record: slurm_job:allocated_gpu:count_user_account
        expr: count(slurm_job_utilization_gpu) by (user, account)
      - record: slurm_job:used_gpu:sum
        expr: sum(slurm_job_utilization_gpu) / 100
      - record: slurm_job:used_gpu:sum_user_account
        expr: sum(slurm_job_utilization_gpu) by (user,account) / 100
      - record: slurm_job:non_idle_gpu:sum_user_account
        expr: count(slurm_job_utilization_gpu > 0) by (user,account)
      - record: slurm_job:power_gpu:sum
        expr: sum(slurm_job_power_gpu)
      - record: slurm_job:power_gpu:sum_user_account
        expr: sum(slurm_job_power_gpu) by (user,account)

prometheus::node_exporter::version: 1.5.0
prometheus::server::version: 2.39.0
prometheus::server::scrape_configs:
  - job_name: node
    scrape_interval: 10s
    scrape_timeout: 10s
    honor_labels: true
    consul_sd_configs:
      - server: 127.0.0.1:8500
        token: "%{hiera('profile::consul::acl_api_token')}"
    relabel_configs:
      - source_labels:
          - __meta_consul_tags
        regex: '.*,node-exporter,.*'
        action: keep
      - source_labels:
          - __meta_consul_node
        target_label: instance
  - job_name: slurm_job
    scrape_interval: 10s
    scrape_timeout: 10s
    honor_labels: true
    consul_sd_configs:
      - server: 127.0.0.1:8500
        token: "%{hiera('profile::consul::acl_api_token')}"
    relabel_configs:
      - source_labels:
          - __meta_consul_tags
        regex: '.*,slurm-job-exporter,.*'
        action: keep
      - source_labels:
          - __meta_consul_node
        target_label: instance
  - job_name: prometheus-slurm-exporter
    scrape_interval: 10s
    scrape_timeout: 10s
    honor_labels: true
    consul_sd_configs:
      - server: 127.0.0.1:8500
        token: "%{hiera('profile::consul::acl_api_token')}"
    relabel_configs:
      - source_labels:
          - __meta_consul_tags
        regex: '.*,slurm-exporter,.*'
        action: keep
      - source_labels:
          - __meta_consul_node
        target_label: instance
  - job_name: jupyterhub
    metrics_path: "/hub/metrics"
    scrape_interval: 10s
    scrape_timeout: 10s
    honor_labels: true
    authorization:
      type: Bearer
      credentials: "%{hiera('jupyterhub::prometheus_token')}"
    consul_sd_configs:
      - server: 127.0.0.1:8500
        token: "%{hiera('profile::consul::acl_api_token')}"
    relabel_configs:
      - source_labels:
          - __meta_consul_tags
        regex: '.*,jupyterhub,.*'
        action: keep
      - source_labels:
          - __meta_consul_node
        target_label: instance

prometheus::storage_retention: '48h'
prometheus::storage_retention_size: '5GB'

prometheus::alertmanager::version: '0.26.0'
# The default value has a syntax issue in the original puppet-prometheus
# https://github.com/voxpupuli/puppet-prometheus/pull/540
prometheus::alertmanager::receivers:
  - name: 'Admin'
    email_configs:
      - to: 'root@localhost'

prometheus::alertmanagers_config:
  - static_configs:
    - targets:
      - "%{hiera('terraform.tag_ip.mgmt.0')}:9093"


profile::squid::server::port: 3128
profile::squid::server::cache_size: 4096
profile::squid::server::cvmfs_acl_regex:
  - '^(cvmfs-.*\.computecanada\.ca)$'
  - '^(cvmfs-.*\.computecanada\.net)$'
  - '^(object-.*\.cloud\.computecanada\.ca)$'
  - '^(.*-cvmfs\.openhtc\.io)$'
  - '^(cvmfs-.*\.genap\.ca)$'
  - '^(.*\.cvmfs\.eessi-infra\.org)$'
  - '^(.*s1\.eessi\.science)$'

profile::cvmfs::client::quota_limit: 4096
profile::cvmfs::client::repositories:
  - pilot.eessi-hpc.org
  - software.eessi.io
  - cvmfs-config.computecanada.ca
  - soft.computecanada.ca
profile::cvmfs::local_user::group: 'cvmfs-reserved'
profile::cvmfs::local_user::uid: 13000004
profile::cvmfs::local_user::gid: 8000131

profile::freeipa::mokey::port: 12345
profile::freeipa::mokey::enable_user_signup: true
profile::freeipa::mokey::require_verify_admin: true
profile::freeipa::mokey::access_tags: "%{alias('profile::users::ldap::access_tags')}"

profile::freeipa::server::id_start: 60001
profile::software_stack::min_uid: "%{alias('profile::freeipa::server::id_start')}"

profile::slurm::base::slurm_version: '24.05'
profile::slurm::base::os_reserved_memory: 512
profile::slurm::controller::autoscale_version: '0.5.1'
profile::slurm::node::enable_tmpfs_mounts: true

profile::accounts::project_regex: '(ctb|def|rpp|rrg)-[a-z0-9_-]*'
profile::users::ldap::access_tags: ['login:sshd', 'node:sshd', 'proxy:jupyterhub-login']
profile::users::ldap::users:
  'user':
    count: "%{alias('terraform.data.nb_users')}"
    passwd: "%{alias('terraform.data.guest_passwd')}"
    groups: ['def-sponsor00']
    manage_password: true

profile::users::local::users:
  "%{alias('terraform.data.sudoer_username')}":
    public_keys: "%{alias('terraform.data.public_keys')}"
    groups: ['adm', 'wheel', 'systemd-journal']
    sudoer: true
    authenticationmethods: 'publickey'


profile::freeipa::base::domain_name: "%{alias('terraform.data.domain_name')}"

profile::slurm::base::cluster_name: "%{alias('terraform.data.cluster_name')}"

profile::freeipa::client::server_ip: "%{alias('terraform.tag_ip.mgmt.0')}"
profile::consul::servers: "%{alias('terraform.tag_ip.puppet')}"

profile::nfs::server::domain_name: "%{hiera('profile::freeipa::base::domain_name')}"
profile::nfs::client::domain_name: "%{hiera('profile::freeipa::base::domain_name')}"
profile::nfs::client::server_ip: "%{alias('terraform.tag_ip.nfs.0')}"
profile::volumes::devices: "%{alias('terraform.self.volumes')}"

profile::reverse_proxy::domain_name: "%{alias('terraform.data.domain_name')}"
profile::reverse_proxy::subdomains:
  ipa: "ipa.int.%{lookup('terraform.data.domain_name')}"
  mokey: "%{lookup('terraform.tag_ip.mgmt.0')}:%{lookup('profile::freeipa::mokey::port')}"
  jupyter: "https://127.0.0.1:8000"

profile::jupyterhub::hub::register_url: "https://mokey.%{lookup('terraform.data.domain_name')}/auth/signup"
profile::jupyterhub::hub::reset_pw_url: "https://mokey.%{lookup('terraform.data.domain_name')}/auth/forgotpw"

profile::gpu::install::passthrough::packages:
  - nvidia-driver-cuda-libs
  - nvidia-driver
  - nvidia-driver-devel
  - nvidia-driver-libs
  - nvidia-driver-NVML
  - nvidia-modprobe
  - nvidia-xconfig
  - nvidia-persistenced
  - nvidia-driver-cuda
